# Advanced-Machine-Learning-Specialization
Deep Dive Into The Modern AI Techniques. You will teach computer to see, draw, read, talk, play games and solve industry problems.

This specialization gives an introduction to deep learning, reinforcement learning, natural language understanding, computer vision and Bayesian methods. Top Kaggle machine learning practitioners and CERN scientists will share their experience of solving real-world problems and help you to fill the gaps between theory and practice. Upon completion of 7 courses you will be able to apply modern machine learning methods in enterprise and understand the caveats of real-world data and settings. Again, welcome to “Intro to Deep Learning” course! We are excited to have you in the class and we are looking forward to your contributions to the learning community.

Deep learning is a fast-growing field of AI focused on using neural networks for complex practical problems. Deep neural networks are used nowadays for object recognition and image analysis, for various modules of self-driving cars, for chatbots and natural language understanding problems.

In this course you will learn the basics of deep learning. We’ll start with a recap of linear models and discuss stochastic optimization methods that are crucial for training deep neural networks. Then you will study all popular building blocks of neural networks including fully connected layers, convolutional and recurrent layers. You will use these building blocks to define complex modern architectures in TensorFlow and Keras frameworks. In the course project you will implement a deep neural network for the task of image captioning which solves the problem of giving a text description for an input image.

Please note that this is an advanced course and we assume basic knowledge of machine learning. You should understand:

Linear regression: mean squared error, analytical solution.
Logistic regression: model, cross-entropy loss, class probability estimation.
Gradient descent for linear models. Derivatives of MSE and cross-entropy loss functions.
The problem of overfitting.
Regularization for linear models.
We will cover all these topics in our recap, but the discussion may be quite tough if you’ve never heard of machine learning before.

Good luck as you get started and we hope you enjoy the course!

Sincerely yours,

Evgeny Sokolov, Nikita Kazeev, Andrey Zimovnov, Sasha Panin and Kate Lobacheva
